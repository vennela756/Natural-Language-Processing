{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Step 1:- Import the required libraries \n\n\nimport numpy as np\nfrom numpy import array\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport string\nimport os\nimport glob\nfrom PIL import Image\nfrom time import time\n\nfrom keras import Input, layers\nfrom keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing import image\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import LSTM, Embedding, Dense, Activation, Flatten, Reshape, Dropout\nfrom keras.layers.wrappers import Bidirectional\nfrom keras.layers.merge import add,concatenate\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.models import Model\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T09:58:24.136116Z","iopub.execute_input":"2022-05-04T09:58:24.136404Z","iopub.status.idle":"2022-05-04T09:58:24.154718Z","shell.execute_reply.started":"2022-05-04T09:58:24.136376Z","shell.execute_reply":"2022-05-04T09:58:24.154021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\ndef Recall(y_true,y_pred):  \n    # y_true = [0   ,1   ,0   ,0   ,0   ,1]\n    # y_pred = [0.2 ,0.4 ,0.3 ,0.2 ,0.4 ,0.3]\n    re = recall_score(y_true, y_pred)\n    return re\n\ndef Precision(y_true,y_pred):  \n    # y_true = [0   ,1   ,0   ,0   ,0   ,1]\n    # y_pred = [0.2 ,0.7 ,0.3 ,0.2 ,0.4 ,0.3]\n    return precision_score(y_true, y_pred)\n\ndef F_score(y_true,y_pred):  \n    # y_true = [0   ,1   ,0   ,0   ,0   ,1]\n    # y_pred = [0.2 ,0.4 ,0.3 ,0.2 ,0.4 ,0.3]\n    return f1_score(y_true, y_pred)\n\ndef Accuracy(y_true,y_pred):  \n    # y_true = [0   ,1   ,0   ,0   ,0   ,1]\n    # y_pred = [0.2 ,0.4 ,0.3 ,0.2 ,0.4 ,0.3]\n    return accuracy_score(y_true, y_pred)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.15658Z","iopub.execute_input":"2022-05-04T09:58:24.156876Z","iopub.status.idle":"2022-05-04T09:58:24.16481Z","shell.execute_reply.started":"2022-05-04T09:58:24.156831Z","shell.execute_reply":"2022-05-04T09:58:24.164118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Step 2 : Data Loading and Pre-Processing\n\ntoken_path = \"../input/flickr8k/Flickr8k.token.txt\"\ntrain_images_path = '../input/flickr8k/Flickr_8k.trainImages.txt'\ntest_images_path = '../input/flickr8k/Flickr_8k.testImages.txt'\nval_images_path = '../input/flickr8k/Flickr_8k.devImages.txt'\nimages_path = '../input/flickr-8k/Images/'\nglove_path = '../input/glove6b/'\n\ndoc = open(token_path,'r').read()\nprint(doc[:410])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.166082Z","iopub.execute_input":"2022-05-04T09:58:24.166487Z","iopub.status.idle":"2022-05-04T09:58:24.180669Z","shell.execute_reply.started":"2022-05-04T09:58:24.16645Z","shell.execute_reply":"2022-05-04T09:58:24.179616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"descriptions = dict()\nfor line in doc.split('\\n'):\n        tokens = line.split()\n        #print(tokens)\n        if len(line) > 2:\n            image_id = tokens[0].split('.')[0]\n            image_desc = ' '.join(tokens[1:])\n            if image_id not in descriptions:\n                descriptions[image_id] = list()\n            descriptions[image_id].append(image_desc)\n            \n#print(descriptions)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.184333Z","iopub.execute_input":"2022-05-04T09:58:24.184794Z","iopub.status.idle":"2022-05-04T09:58:24.301558Z","shell.execute_reply.started":"2022-05-04T09:58:24.184741Z","shell.execute_reply":"2022-05-04T09:58:24.30081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table = str.maketrans('', '', string.punctuation)\nfor key, desc_list in descriptions.items():\n    for i in range(len(desc_list)):\n        desc = desc_list[i]\n        desc = desc.split()\n        desc = [word.lower() for word in desc]\n        desc = [w.translate(table) for w in desc]\n        desc_list[i] =  ' '.join(desc)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.302824Z","iopub.execute_input":"2022-05-04T09:58:24.30317Z","iopub.status.idle":"2022-05-04T09:58:24.639029Z","shell.execute_reply.started":"2022-05-04T09:58:24.303131Z","shell.execute_reply":"2022-05-04T09:58:24.638263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Lets visualize and example image\npic = '1000268201_693b08cb0e.jpg'\nx=plt.imread(images_path+pic)\nplt.imshow(x)\nplt.show()\ndescriptions['1000268201_693b08cb0e']","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.640569Z","iopub.execute_input":"2022-05-04T09:58:24.640847Z","iopub.status.idle":"2022-05-04T09:58:24.837348Z","shell.execute_reply.started":"2022-05-04T09:58:24.640812Z","shell.execute_reply":"2022-05-04T09:58:24.83657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Divide INTO POSITIVE AND NEGATIVE EXAMPLES**","metadata":{}},{"cell_type":"code","source":"vocabulary = set()\nfor key in descriptions.keys():\n        [vocabulary.update(d.split()) for d in descriptions[key]]\nprint('Original Vocabulary Size: %d' % len(vocabulary))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.838871Z","iopub.execute_input":"2022-05-04T09:58:24.839363Z","iopub.status.idle":"2022-05-04T09:58:24.907598Z","shell.execute_reply.started":"2022-05-04T09:58:24.83933Z","shell.execute_reply":"2022-05-04T09:58:24.906841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lines = list()\nfor key, desc_list in descriptions.items():\n    for desc in desc_list:\n        lines.append(key + ' ' + desc)\nnew_descriptions = '\\n'.join(lines)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.908851Z","iopub.execute_input":"2022-05-04T09:58:24.909111Z","iopub.status.idle":"2022-05-04T09:58:24.931404Z","shell.execute_reply.started":"2022-05-04T09:58:24.909077Z","shell.execute_reply":"2022-05-04T09:58:24.930463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(new_descriptions[:450])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.93441Z","iopub.execute_input":"2022-05-04T09:58:24.934757Z","iopub.status.idle":"2022-05-04T09:58:24.943199Z","shell.execute_reply.started":"2022-05-04T09:58:24.934721Z","shell.execute_reply":"2022-05-04T09:58:24.942448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = open(train_images_path,'r').read()\ndataset1 = list()\nfor line in doc.split('\\n'):\n    if len(line) > 1:\n        identifier = line.split('.')[0]\n        dataset1.append(identifier)\n\ntrain = set(dataset1)\n\ndoc = open(test_images_path,'r').read()\ndataset2 = list()\nfor line in doc.split('\\n'):\n    if len(line) > 1:\n        identifier = line.split('.')[0]\n        dataset2.append(identifier)\n\ntest = set(dataset2)\n\ndoc = open(val_images_path,'r').read()\ndataset3 = list()\nfor line in doc.split('\\n'):\n    if len(line) > 1:\n        identifier = line.split('.')[0]\n        dataset3.append(identifier)\n\nval = set(dataset3)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.94484Z","iopub.execute_input":"2022-05-04T09:58:24.945105Z","iopub.status.idle":"2022-05-04T09:58:24.966456Z","shell.execute_reply.started":"2022-05-04T09:58:24.945072Z","shell.execute_reply":"2022-05-04T09:58:24.965823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(list(train)[:5])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.967967Z","iopub.execute_input":"2022-05-04T09:58:24.968143Z","iopub.status.idle":"2022-05-04T09:58:24.97408Z","shell.execute_reply.started":"2022-05-04T09:58:24.968121Z","shell.execute_reply":"2022-05-04T09:58:24.971919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = glob.glob(images_path + '*.jpg')\ntrain_images = set(open(train_images_path, 'r').read().strip().split('\\n'))\ntrain_img = []\nfor i in img: \n    if i[len(images_path):] in train_images:\n        train_img.append(i)\n\ntest_images = set(open(test_images_path, 'r').read().strip().split('\\n'))\ntest_img = []\nfor i in img: \n    if i[len(images_path):] in test_images: \n        test_img.append(i)\n        \nval_images = set(open(val_images_path, 'r').read().strip().split('\\n'))\nval_img = []\nfor i in img: \n    if i[len(images_path):] in val_images: \n        val_img.append(i)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:24.975398Z","iopub.execute_input":"2022-05-04T09:58:24.975812Z","iopub.status.idle":"2022-05-04T09:58:25.021761Z","shell.execute_reply.started":"2022-05-04T09:58:24.975764Z","shell.execute_reply":"2022-05-04T09:58:25.021102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_img[:2])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:25.02336Z","iopub.execute_input":"2022-05-04T09:58:25.023841Z","iopub.status.idle":"2022-05-04T09:58:25.02842Z","shell.execute_reply.started":"2022-05-04T09:58:25.023807Z","shell.execute_reply":"2022-05-04T09:58:25.027595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_descriptions = dict()\ntest_descriptions = dict()\nval_descriptions = dict()\nfor line in new_descriptions.split('\\n'):\n    tokens = line.split()\n    image_id, image_desc = tokens[0], tokens[1:]\n    if image_id in train:\n        if image_id not in train_descriptions:\n            train_descriptions[image_id] = list()\n        #desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n        desc = ' '.join(image_desc)\n        train_descriptions[image_id].append(desc)\n    elif image_id in test:\n        if image_id not in test_descriptions:\n            test_descriptions[image_id] = list()\n        #desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n        desc = ' '.join(image_desc)\n        test_descriptions[image_id].append(desc)\n    elif image_id in val:\n        if image_id not in val_descriptions:\n            val_descriptions[image_id] = list()\n        #desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n        desc = ' '.join(image_desc)\n        val_descriptions[image_id].append(desc)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:25.029867Z","iopub.execute_input":"2022-05-04T09:58:25.030457Z","iopub.status.idle":"2022-05-04T09:58:25.13668Z","shell.execute_reply.started":"2022-05-04T09:58:25.030418Z","shell.execute_reply":"2022-05-04T09:58:25.135956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_train_captions = []\nfor key, val in train_descriptions.items():\n    for cap in val:\n        all_train_captions.append(cap)\n        \nall_test_captions = []\nfor key, val in test_descriptions.items():\n    for cap in val:\n        all_test_captions.append(cap)\n        \nall_val_captions = []\nfor key, val in val_descriptions.items():\n    for cap in val:\n        all_val_captions.append(cap)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:25.138034Z","iopub.execute_input":"2022-05-04T09:58:25.138273Z","iopub.status.idle":"2022-05-04T09:58:25.151535Z","shell.execute_reply.started":"2022-05-04T09:58:25.13824Z","shell.execute_reply":"2022-05-04T09:58:25.150836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**train_descriptions**\n\n{'1000268201_693b08cb0e': ['startseq a child in a pink dress is climbing up a set of stairs in an entry way endseq', 'startseq a girl going into a wooden building endseq', 'startseq a little girl climbing into a wooden playhouse endseq', 'startseq a little girl climbing the stairs to her playhouse endseq', 'startseq a little girl in a pink dress going into a wooden cabin endseq']","metadata":{}},{"cell_type":"code","source":"a = len(all_train_captions)\nprint(a)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:25.152623Z","iopub.execute_input":"2022-05-04T09:58:25.153426Z","iopub.status.idle":"2022-05-04T09:58:25.160825Z","shell.execute_reply.started":"2022-05-04T09:58:25.153387Z","shell.execute_reply":"2022-05-04T09:58:25.159904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate negative samples\n\nimport random\nfrom random import randrange\nrandom.seed(40)\n\npos_neg_train_descriptions = dict()\nfor key, val in train_descriptions.items():\n    pos_neg_descriptions = dict()\n    pos_neg_descriptions[0] = list()\n    pos_neg_descriptions[1] = val\n    \n    for i in range(5):\n        rand_cap = None\n        while(True):\n            i = randrange(len(all_train_captions))\n            rand_cap = all_train_captions[i]\n            if rand_cap not in val:\n                break\n            print(\"Collision\")\n        pos_neg_descriptions[0].append(rand_cap)\n    pos_neg_train_descriptions[key] = pos_neg_descriptions\n    \n    \npos_neg_test_descriptions = dict()\nfor key, val in test_descriptions.items():\n    pos_neg_descriptions = dict()\n    pos_neg_descriptions[0] = list()\n    pos_neg_descriptions[1] = val\n    \n    for i in range(5):\n        rand_cap = None\n        while(True):\n            i = randrange(len(all_test_captions))\n            rand_cap = all_test_captions[i]\n            if rand_cap not in val:\n                break\n            print(\"Collision\")\n        pos_neg_descriptions[0].append(rand_cap)\n    pos_neg_test_descriptions[key] = pos_neg_descriptions\n    \n    \n    \npos_neg_val_descriptions = dict()\nfor key, val in val_descriptions.items():\n    pos_neg_descriptions = dict()\n    pos_neg_descriptions[0] = list()\n    pos_neg_descriptions[1] = val\n    \n    for i in range(5):\n        rand_cap = None\n        while(True):\n            i = randrange(len(all_val_captions))\n            rand_cap = all_val_captions[i]\n            if rand_cap not in val:\n                break\n            print(\"Collision\")\n        pos_neg_descriptions[0].append(rand_cap)\n    pos_neg_val_descriptions[key] = pos_neg_descriptions\n    \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:25.162632Z","iopub.execute_input":"2022-05-04T09:58:25.162925Z","iopub.status.idle":"2022-05-04T09:58:25.273346Z","shell.execute_reply.started":"2022-05-04T09:58:25.162892Z","shell.execute_reply":"2022-05-04T09:58:25.27261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count_threshold = 10\nword_counts = {}\nnsents = 0\nfor sent in all_train_captions:\n    nsents += 1\n    for w in sent.split(' '):\n        word_counts[w] = word_counts.get(w, 0) + 1\n        \nfor sent in all_test_captions:\n    nsents += 1\n    for w in sent.split(' '):\n        word_counts[w] = word_counts.get(w, 0) + 1\n        \nfor sent in all_val_captions:\n    nsents += 1\n    for w in sent.split(' '):\n        word_counts[w] = word_counts.get(w, 0) + 1\n        \nvocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n\nprint('Vocabulary = %d' % (len(vocab)))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:25.274553Z","iopub.execute_input":"2022-05-04T09:58:25.275116Z","iopub.status.idle":"2022-05-04T09:58:25.455401Z","shell.execute_reply.started":"2022-05-04T09:58:25.275078Z","shell.execute_reply":"2022-05-04T09:58:25.45464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ixtoword = {}\nwordtoix = {}\nix = 1\nfor w in vocab:\n    wordtoix[w] = ix\n    ixtoword[ix] = w\n    ix += 1\n\nvocab_size = len(ixtoword) + 1\n\nall_desc = list()\nfor key in train_descriptions.keys():\n    [all_desc.append(d) for d in train_descriptions[key]]\nfor key in test_descriptions.keys():\n    [all_desc.append(d) for d in test_descriptions[key]]\nfor key in val_descriptions.keys():\n    [all_desc.append(d) for d in val_descriptions[key]]\n    \nlines = all_desc\nmax_length = max(len(d.split()) for d in lines)\n\nprint('Description Length: %d' % max_length)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:25.456738Z","iopub.execute_input":"2022-05-04T09:58:25.457093Z","iopub.status.idle":"2022-05-04T09:58:25.512279Z","shell.execute_reply.started":"2022-05-04T09:58:25.457052Z","shell.execute_reply":"2022-05-04T09:58:25.511525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 3**","metadata":{}},{"cell_type":"code","source":"embeddings_index = {} \nf = open(os.path.join(glove_path, 'glove.6B.200d.txt'), encoding=\"utf-8\")\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\n    \nembedding_dim = 200\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, i in wordtoix.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:25.513708Z","iopub.execute_input":"2022-05-04T09:58:25.514001Z","iopub.status.idle":"2022-05-04T09:58:46.602289Z","shell.execute_reply.started":"2022-05-04T09:58:25.513964Z","shell.execute_reply":"2022-05-04T09:58:46.601548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**STEP 4**","metadata":{}},{"cell_type":"code","source":"model = InceptionV3(weights='imagenet')\n\nmodel_new = Model(model.input, model.layers[-2].output)\n\ndef preprocess(image_path):\n    img = image.load_img(image_path, target_size=(299, 299))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    return x\n\n\n\n\ndef encode(image):\n    image = preprocess(image) \n    fea_vec = model_new.predict(image) \n    fea_vec = np.reshape(fea_vec, fea_vec.shape[1])\n    return fea_vec\n\nencoding_train = {}\nfor img in train_img:\n    encoding_train[img[len(images_path):]] = encode(img)\ntrain_features = encoding_train\n\nencoding_test = {}\nfor img in test_img:\n    encoding_test[img[len(images_path):]] = encode(img)\ntest_features = encoding_test\n\nencoding_val = {}\nfor img in val_img:\n    encoding_val[img[len(images_path):]] = encode(img)\nval_features = encoding_val","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:58:46.603696Z","iopub.execute_input":"2022-05-04T09:58:46.603971Z","iopub.status.idle":"2022-05-04T10:16:44.685524Z","shell.execute_reply.started":"2022-05-04T09:58:46.603938Z","shell.execute_reply":"2022-05-04T10:16:44.684738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess1(path):\n    img = image.load_img(path, target_size=(299, 299))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:21:21.656596Z","iopub.execute_input":"2022-05-04T11:21:21.656891Z","iopub.status.idle":"2022-05-04T11:21:21.661862Z","shell.execute_reply.started":"2022-05-04T11:21:21.656862Z","shell.execute_reply":"2022-05-04T11:21:21.660849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_img)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:20:23.934638Z","iopub.execute_input":"2022-05-04T11:20:23.935363Z","iopub.status.idle":"2022-05-04T11:20:23.946349Z","shell.execute_reply.started":"2022-05-04T11:20:23.935325Z","shell.execute_reply":"2022-05-04T11:20:23.945524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(encoding_train))\nprint(len(encoding_test))\nprint(len(encoding_val))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T10:16:44.686749Z","iopub.execute_input":"2022-05-04T10:16:44.687029Z","iopub.status.idle":"2022-05-04T10:16:44.693153Z","shell.execute_reply.started":"2022-05-04T10:16:44.686994Z","shell.execute_reply":"2022-05-04T10:16:44.692455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#take the images as input\n#construct the archtitecture => LeNet5, VGG16\n#train the model\n#calculate accuracy\n\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nimport os\n\nimport keras\n\nfrom numpy.random import seed\nseed(1)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#import keras\n#from keras.models import Sequential\n#from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n#from keras.preprocessing.image import ImageDataGenerator\n \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\n#import keras\nfrom tensorflow.keras.models import Sequential, Model,load_model\nfrom tensorflow.keras.optimizers import SGD, RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom tensorflow.keras.layers import Input,Dropout, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.applications.densenet import DenseNet201, DenseNet121\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport matplotlib.pyplot as plt\n\n\n\n\n########### MODEL ###############\nfrom keras.layers import Dropout\nfrom tensorflow.keras.applications import InceptionV3, Xception\n\nbase_model = Xception(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.6,name='dropout_fc2')(x)\npredictions = Dense(200, activation='softmax')(x)\n\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:11:08.641481Z","iopub.execute_input":"2022-05-08T10:11:08.642157Z","iopub.status.idle":"2022-05-08T10:11:13.996618Z","shell.execute_reply.started":"2022-05-08T10:11:08.642108Z","shell.execute_reply":"2022-05-08T10:11:13.995547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs1 = Input(shape=(2048,))\nfe1 = Dropout(0.5)(inputs1)\nfe2 = Dense(256, activation='relu')(fe1)\n\ninputs2 = Input(shape=(max_length,))\n\nse1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\nse2 = Dropout(0.5)(se1)\nse3 = LSTM(256)(se2)\n\n\n\ndecoder1 = concatenate([fe2, se3])\ndecoder2 = Dense(256, activation='relu')(decoder1)\noutputs = Dense(1, activation='sigmoid')(decoder2)\n\nmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\nmodel.summary()\n\nmodel.layers[2].set_weights([embedding_matrix])\nmodel.layers[2].trainable = False\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:03:47.303733Z","iopub.execute_input":"2022-05-04T11:03:47.304329Z","iopub.status.idle":"2022-05-04T11:03:48.022873Z","shell.execute_reply.started":"2022-05-04T11:03:47.304289Z","shell.execute_reply":"2022-05-04T11:03:48.021182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**STEP 5**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.config.run_functions_eagerly(True)\n\n                \ndef data_generator(descriptions, train_features, wordtoix, max_length, batch_size):\n    X1, X2, y = list(), list(), list()\n    n=0\n    # loop for ever over images\n    while 1:\n        for key, desc in descriptions.items():\n            n+=1\n            # retrieve the photo feature\n            photo = train_features[key +'.jpg']\n            \n            neg_captions = desc[0]\n            pos_captions = desc[1]\n            for i in range(5):\n                #print(pos_captions)\n                pos_seq = [wordtoix[word] for word in pos_captions[i].split(' ') if word in wordtoix]\n                pos_pad_seq = pad_sequences([pos_seq], maxlen=max_length, padding='post')[0]\n                \n                X1.append(photo)\n                X2.append(pos_pad_seq)\n                y.append(1)\n                \n                neg_seq = [wordtoix[word] for word in neg_captions[i].split(' ') if word in wordtoix]\n                neg_pad_seq = pad_sequences([neg_seq], maxlen=max_length, padding='post')[0]\n                \n                X1.append(photo)\n                X2.append(neg_pad_seq)\n                y.append(0)  \n\n            if n==batch_size:\n                yield ([array(X1), array(X2)], array(y))\n                X1, X2, y = list(), list(), list()\n                n=0\n\n\nepochs = 30\nbatch_size = 4\nsteps = len(pos_neg_train_descriptions)//batch_size\nval_steps = len(pos_neg_test_descriptions)//batch_size\n\ntrain_generator = data_generator(pos_neg_train_descriptions, train_features, wordtoix, max_length, batch_size)\ntest_generator  = data_generator(pos_neg_test_descriptions, test_features, wordtoix, max_length, batch_size)\nval_generator  = data_generator(pos_neg_val_descriptions, val_features, wordtoix, max_length, batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T10:16:45.492771Z","iopub.execute_input":"2022-05-04T10:16:45.49309Z","iopub.status.idle":"2022-05-04T10:16:45.509178Z","shell.execute_reply.started":"2022-05-04T10:16:45.493051Z","shell.execute_reply":"2022-05-04T10:16:45.508445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\nes=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\nmc = ModelCheckpoint(\"Caption.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nmodel.fit_generator(train_generator, epochs=epochs, steps_per_epoch=steps, validation_data=test_generator, validation_steps =val_steps, shuffle=True, callbacks=[es,mc], verbose=1) #15 epochs","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:03:51.63647Z","iopub.execute_input":"2022-05-04T11:03:51.636725Z","iopub.status.idle":"2022-05-04T11:08:32.03392Z","shell.execute_reply.started":"2022-05-04T11:03:51.636698Z","shell.execute_reply":"2022-05-04T11:08:32.032636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"Captions.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T10:17:02.727717Z","iopub.status.idle":"2022-05-04T10:17:02.728345Z","shell.execute_reply.started":"2022-05-04T10:17:02.728092Z","shell.execute_reply":"2022-05-04T10:17:02.728119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nmodel_path = \"/kaggle/input/model6/Caption (1).h5\"\nmodel = keras.models.load_model(model_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:48:06.35327Z","iopub.execute_input":"2022-05-04T12:48:06.35355Z","iopub.status.idle":"2022-05-04T12:48:14.900302Z","shell.execute_reply.started":"2022-05-04T12:48:06.353518Z","shell.execute_reply":"2022-05-04T12:48:14.899511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = model.layers[-2].get_weights()\nprint(a[0].shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T10:17:02.731678Z","iopub.status.idle":"2022-05-04T10:17:02.732366Z","shell.execute_reply.started":"2022-05-04T10:17:02.732106Z","shell.execute_reply":"2022-05-04T10:17:02.732132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(val_generator, steps = val_steps)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T10:39:02.174559Z","iopub.execute_input":"2022-05-04T10:39:02.175405Z","iopub.status.idle":"2022-05-04T10:39:07.325519Z","shell.execute_reply.started":"2022-05-04T10:39:02.175362Z","shell.execute_reply":"2022-05-04T10:39:07.324709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For Overall\ndef generate_y(gen, steps):\n    y_true = np.array([])\n    y_pred = np.array([])\n    for i in range(steps):\n        x,y = next(gen)\n        y_true = np.append(y_true, y)\n        y_pred = np.append(y_pred, model.predict(x))\n    \n    return y_true,y_pred\n\ny_true, y_pred  = generate_y(val_generator, val_steps)\ny_pred  = np.round(y_pred)\npos_indices = np.where(y_true == 1)[0]\nneg_indices = np.where(y_true == 0)[0]\n\n\nprecision = Precision(y_true,y_pred)\nprint(\"Precision on Validation Dataset : \", precision)\n\nrecall = Recall(y_true,y_pred)\nprint(\"Recall on Validation Dataset    : \", recall)\n\nf_score = F_score(y_true,y_pred)\nprint(\"F_score on Validation Dataset   : \", f_score)\n\naccuracy = Accuracy(y_true,y_pred)\nprint(\"Accuracy on Validation Dataset  : \", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T10:20:04.230344Z","iopub.execute_input":"2022-05-04T10:20:04.230618Z","iopub.status.idle":"2022-05-04T10:20:18.886149Z","shell.execute_reply.started":"2022-05-04T10:20:04.23059Z","shell.execute_reply":"2022-05-04T10:20:18.884688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For Positive and negative samples\n\npos_y_true = y_true[pos_indices]\npos_y_pred = y_pred[pos_indices]\n\nneg_y_true = y_true[neg_indices]\nneg_y_pred = y_pred[neg_indices]\n\n\n# POSITIVE\n\n\npos_accuracy = Accuracy(pos_y_true, pos_y_pred)\nprint(\"Accuracy on Validation Dataset(only 1-class) : \", pos_accuracy)\n\n\n\n# NEGATIVE\n\nneg_accuracy = Accuracy(neg_y_true, neg_y_pred)\nprint(\"Accuracy on Validation Dataset(only 0-class) : \", neg_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T10:22:44.257639Z","iopub.execute_input":"2022-05-04T10:22:44.258198Z","iopub.status.idle":"2022-05-04T10:22:44.267253Z","shell.execute_reply.started":"2022-05-04T10:22:44.258161Z","shell.execute_reply":"2022-05-04T10:22:44.266502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_caption(caption):\n    \n    seq = [wordtoix[word] for word in caption.split(' ') if word in wordtoix]\n    pad_seq = pad_sequences([seq], maxlen=max_length)[0]\n    return np.array([pad_seq])\n\n#key = '103106960_e8a41d64f8.jpg'\npath = \"/kaggle/input/picture1/photo-1455577380025-4321f1e1dca7.jpg\"\nX1 = np.array([encode(path)])\n#X1 = np.array([val_features[key]])\nX2 = decode_caption('red trees')\nx=plt.imread(path)\nplt.imshow(x)\nplt.show()\ny = model.predict([X1,X2])\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:47:55.536683Z","iopub.execute_input":"2022-05-04T12:47:55.537282Z","iopub.status.idle":"2022-05-04T12:47:55.622606Z","shell.execute_reply.started":"2022-05-04T12:47:55.537189Z","shell.execute_reply":"2022-05-04T12:47:55.62167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display Image, Caption , Actual answer, Predicted answer\n\ndesc = pos_neg_val_descriptions\nmy_path = images_path\nn = 0\nfor k,v in desc.items():\n    X1 = []\n    X2 = []\n    y = []\n    n += 1\n    pic = k + \".jpg\"\n    print(pic)\n    x=plt.imread(my_path+pic)\n    plt.imshow(x)\n    plt.show()\n    photo = val_features[pic]\n    neg_captions = v[0]\n    pos_captions = v[1]\n    captions = []\n    for i in range(5):\n        captions.append(pos_captions[i])\n        pos_seq = [wordtoix[word] for word in pos_captions[i].split(' ') if word in wordtoix]\n        pos_pad_seq = pad_sequences([pos_seq], maxlen=max_length)[0]\n                \n        X1.append(photo)\n        X2.append(pos_pad_seq)\n        y.append([1])\n          \n        captions.append(neg_captions[i])\n        neg_seq = [wordtoix[word] for word in neg_captions[i].split(' ') if word in wordtoix]\n        neg_pad_seq = pad_sequences([neg_seq], maxlen=max_length)[0]\n                \n        X1.append(photo)\n        X2.append(neg_pad_seq)\n        y.append([0])\n    X = [np.array(X1),np.array(X2)]\n    y_true = np.array(y)\n    #print(X.shape)\n    y_pred = model.predict(X)\n    y_pred1 = np.round(y_pred).astype(int)\n    #y_pred = model.predict(X)\n\n    for i in range(10):\n        print(captions[i])\n        print(\"Actual Answer    : \", y_true[i][0])\n        print(\"Predicted Answer : \", y_pred[i][0], \" => \", y_pred1[i][0])\n        print()\n        \n    if(n == 10):\n        break\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T10:26:14.492576Z","iopub.execute_input":"2022-05-04T10:26:14.492868Z","iopub.status.idle":"2022-05-04T10:26:17.655796Z","shell.execute_reply.started":"2022-05-04T10:26:14.492838Z","shell.execute_reply":"2022-05-04T10:26:17.655055Z"},"trusted":true},"execution_count":null,"outputs":[]}]}